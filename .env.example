# TikTok Chat Reader Environment Variables

# OpenAI API Key (required for OpenAI features)
# Get one at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key

# TikTok Session ID (optional)
# Required for certain TikTok API features
# SESSIONID=your_tiktok_session_id

# Ollama Host (optional, for using Ollama LLM)
# If you're running Ollama locally outside Docker: http://host.docker.internal:11434
# If you're running Ollama in another container: http://ollama:11434
# OLLAMA_HOST=http://your-ollama-server:11434

# Rate limiting (optional)
# Set to 'true' to enable rate limiting
# ENABLE_RATE_LIMIT=true

# Port configuration (defaults to 8081)
PORT=8081
